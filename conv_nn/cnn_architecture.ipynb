{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "126fb471",
      "metadata": {
        "id": "126fb471"
      },
      "source": [
        "# CNN Architecture and Performance on Fashion MINST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b87c5fcb",
      "metadata": {
        "id": "b87c5fcb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0d1457d",
      "metadata": {
        "id": "b0d1457d",
        "outputId": "66ae0675-c1d9-48f6-8702-09709cb7fbf4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7e6062fd",
      "metadata": {
        "id": "7e6062fd"
      },
      "outputs": [],
      "source": [
        "# spliting training set and validation set\n",
        "(X_train, y_train), (X_valid, y_valid) = (X_train_full[:50000], y_train_full[:50000]), (X_train_full[50000:], y_train_full[50000:])\n",
        "X_valid.shape\n",
        "\n",
        "# add channel dimension of 1\n",
        "X_train= np.expand_dims(X_train, -1)\n",
        "X_valid= np.expand_dims(X_valid, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "59f60dd8",
      "metadata": {
        "id": "59f60dd8",
        "outputId": "25b277e1-6cdf-4987-934c-a3a280b05f5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Create a CNN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(64, 7, activation= 'relu', padding= \"same\", input_shape= [28, 28, 1]),\n",
        "    tf.keras.layers.MaxPooling2D(2),\n",
        "    tf.keras.layers.Conv2D(128, 3, activation= 'relu', padding= \"same\"),\n",
        "    tf.keras.layers.Conv2D(128, 3, activation= 'relu', padding= \"same\"),\n",
        "    tf.keras.layers.MaxPooling2D(2),\n",
        "    tf.keras.layers.Conv2D(256, 3, activation= 'relu', padding= \"same\"),\n",
        "    tf.keras.layers.Conv2D(256, 3, activation= 'relu', padding= \"same\"),\n",
        "    tf.keras.layers.MaxPooling2D(2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation= 'relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(64, activation= 'relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation= 'softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "dd27e859",
      "metadata": {
        "id": "dd27e859"
      },
      "outputs": [],
      "source": [
        "model.compile(loss= 'sparse_categorical_crossentropy',\n",
        "              optimizer= 'adam',\n",
        "              metrics= ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5e8a7a53",
      "metadata": {
        "id": "5e8a7a53",
        "outputId": "0045a1e1-0719-48fd-9644-123c3bda0a95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 11ms/step - accuracy: 0.4766 - loss: 1.4953 - val_accuracy: 0.8179 - val_loss: 0.4854\n",
            "Epoch 2/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.8022 - loss: 0.5701 - val_accuracy: 0.8666 - val_loss: 0.3686\n",
            "Epoch 3/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8371 - loss: 0.4703 - val_accuracy: 0.8659 - val_loss: 0.3566\n",
            "Epoch 4/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8527 - loss: 0.4222 - val_accuracy: 0.8835 - val_loss: 0.3275\n",
            "Epoch 5/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8606 - loss: 0.4047 - val_accuracy: 0.8758 - val_loss: 0.3505\n",
            "Epoch 6/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8679 - loss: 0.3890 - val_accuracy: 0.8743 - val_loss: 0.3402\n",
            "Epoch 7/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8665 - loss: 0.3872 - val_accuracy: 0.8836 - val_loss: 0.3207\n",
            "Epoch 8/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8726 - loss: 0.3648 - val_accuracy: 0.8782 - val_loss: 0.3326\n",
            "Epoch 9/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8744 - loss: 0.3624 - val_accuracy: 0.8857 - val_loss: 0.3186\n",
            "Epoch 10/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8733 - loss: 0.3713 - val_accuracy: 0.8853 - val_loss: 0.3258\n",
            "Epoch 11/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8812 - loss: 0.3516 - val_accuracy: 0.8695 - val_loss: 0.3594\n",
            "Epoch 12/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8807 - loss: 0.3548 - val_accuracy: 0.8780 - val_loss: 0.3371\n",
            "Epoch 13/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8830 - loss: 0.3389 - val_accuracy: 0.8890 - val_loss: 0.3199\n",
            "Epoch 14/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8814 - loss: 0.3484 - val_accuracy: 0.8665 - val_loss: 0.3849\n",
            "Epoch 15/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8826 - loss: 0.3402 - val_accuracy: 0.8884 - val_loss: 0.3274\n",
            "Epoch 16/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8825 - loss: 0.3459 - val_accuracy: 0.8800 - val_loss: 0.3377\n",
            "Epoch 17/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8809 - loss: 0.3527 - val_accuracy: 0.8804 - val_loss: 0.3391\n",
            "Epoch 18/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8850 - loss: 0.3379 - val_accuracy: 0.8864 - val_loss: 0.3213\n",
            "Epoch 19/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8805 - loss: 0.3534 - val_accuracy: 0.8816 - val_loss: 0.3416\n",
            "Epoch 20/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8783 - loss: 0.3686 - val_accuracy: 0.8865 - val_loss: 0.3480\n",
            "Epoch 21/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8829 - loss: 0.3412 - val_accuracy: 0.8910 - val_loss: 0.3191\n",
            "Epoch 22/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8816 - loss: 0.3545 - val_accuracy: 0.8795 - val_loss: 0.3585\n",
            "Epoch 23/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8861 - loss: 0.3305 - val_accuracy: 0.8832 - val_loss: 0.3363\n",
            "Epoch 24/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8859 - loss: 0.3402 - val_accuracy: 0.8862 - val_loss: 0.3358\n",
            "Epoch 25/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8876 - loss: 0.3397 - val_accuracy: 0.8772 - val_loss: 0.3751\n",
            "Epoch 26/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8875 - loss: 0.3385 - val_accuracy: 0.8857 - val_loss: 0.3486\n",
            "Epoch 27/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8874 - loss: 0.3359 - val_accuracy: 0.8808 - val_loss: 0.3340\n",
            "Epoch 28/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8886 - loss: 0.3389 - val_accuracy: 0.8826 - val_loss: 0.3421\n",
            "Epoch 29/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.3427 - val_accuracy: 0.8734 - val_loss: 0.3698\n",
            "Epoch 30/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8768 - loss: 0.3746 - val_accuracy: 0.8876 - val_loss: 0.3375\n",
            "Epoch 31/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8868 - loss: 0.3426 - val_accuracy: 0.8804 - val_loss: 0.3709\n",
            "Epoch 32/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8779 - loss: 0.3791 - val_accuracy: 0.8823 - val_loss: 0.3781\n",
            "Epoch 33/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8759 - loss: 0.3835 - val_accuracy: 0.8825 - val_loss: 0.3515\n",
            "Epoch 34/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8851 - loss: 0.3565 - val_accuracy: 0.8842 - val_loss: 0.3651\n",
            "Epoch 35/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8746 - loss: 0.3856 - val_accuracy: 0.8821 - val_loss: 0.3613\n",
            "Epoch 36/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.3505 - val_accuracy: 0.8808 - val_loss: 0.3731\n",
            "Epoch 37/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8809 - loss: 0.3775 - val_accuracy: 0.8819 - val_loss: 0.3624\n",
            "Epoch 38/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8715 - loss: 0.3994 - val_accuracy: 0.8796 - val_loss: 0.3538\n",
            "Epoch 39/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8789 - loss: 0.3787 - val_accuracy: 0.8656 - val_loss: 0.4132\n",
            "Epoch 40/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8721 - loss: 0.4134 - val_accuracy: 0.8873 - val_loss: 0.3363\n",
            "Epoch 41/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8782 - loss: 0.3807 - val_accuracy: 0.8851 - val_loss: 0.3643\n",
            "Epoch 42/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8765 - loss: 0.3814 - val_accuracy: 0.8808 - val_loss: 0.3884\n",
            "Epoch 43/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8729 - loss: 0.4168 - val_accuracy: 0.8832 - val_loss: 0.3559\n",
            "Epoch 44/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8751 - loss: 0.3800 - val_accuracy: 0.8771 - val_loss: 0.3944\n",
            "Epoch 45/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8762 - loss: 0.3836 - val_accuracy: 0.8895 - val_loss: 0.3439\n",
            "Epoch 46/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8821 - loss: 0.3667 - val_accuracy: 0.8893 - val_loss: 0.3802\n",
            "Epoch 47/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8790 - loss: 0.3855 - val_accuracy: 0.8791 - val_loss: 0.3928\n",
            "Epoch 48/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8779 - loss: 0.3849 - val_accuracy: 0.8814 - val_loss: 0.3703\n",
            "Epoch 49/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8754 - loss: 0.3959 - val_accuracy: 0.8693 - val_loss: 0.3650\n",
            "Epoch 50/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8727 - loss: 0.4010 - val_accuracy: 0.8637 - val_loss: 0.4173\n",
            "Epoch 51/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8702 - loss: 0.4127 - val_accuracy: 0.8846 - val_loss: 0.3659\n",
            "Epoch 52/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8691 - loss: 0.4245 - val_accuracy: 0.8717 - val_loss: 0.4299\n",
            "Epoch 53/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8746 - loss: 0.4018 - val_accuracy: 0.8828 - val_loss: 0.3796\n",
            "Epoch 54/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8622 - loss: 0.4565 - val_accuracy: 0.8751 - val_loss: 0.3814\n",
            "Epoch 55/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8673 - loss: 0.4295 - val_accuracy: 0.8543 - val_loss: 0.4553\n",
            "Epoch 56/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8573 - loss: 0.4704 - val_accuracy: 0.8781 - val_loss: 0.4238\n",
            "Epoch 57/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8676 - loss: 0.4324 - val_accuracy: 0.8762 - val_loss: 0.3903\n",
            "Epoch 58/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8626 - loss: 0.4477 - val_accuracy: 0.8485 - val_loss: 0.4426\n",
            "Epoch 59/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.4102 - val_accuracy: 0.8764 - val_loss: 0.4111\n",
            "Epoch 60/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8713 - loss: 0.4100 - val_accuracy: 0.8790 - val_loss: 0.3850\n",
            "Epoch 61/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8773 - loss: 0.3917 - val_accuracy: 0.8780 - val_loss: 0.4139\n",
            "Epoch 62/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8733 - loss: 0.4122 - val_accuracy: 0.8680 - val_loss: 0.4073\n",
            "Epoch 63/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8660 - loss: 0.4552 - val_accuracy: 0.8833 - val_loss: 0.3712\n",
            "Epoch 64/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8666 - loss: 0.4370 - val_accuracy: 0.8732 - val_loss: 0.4164\n",
            "Epoch 65/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8649 - loss: 0.4325 - val_accuracy: 0.8726 - val_loss: 0.4195\n",
            "Epoch 66/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8532 - loss: 0.5007 - val_accuracy: 0.8786 - val_loss: 0.3832\n",
            "Epoch 67/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8707 - loss: 0.4086 - val_accuracy: 0.8866 - val_loss: 0.3938\n",
            "Epoch 68/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8631 - loss: 0.4515 - val_accuracy: 0.8777 - val_loss: 0.3918\n",
            "Epoch 69/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8663 - loss: 0.4360 - val_accuracy: 0.8743 - val_loss: 0.3758\n",
            "Epoch 70/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8544 - loss: 0.4727 - val_accuracy: 0.8536 - val_loss: 0.4528\n",
            "Epoch 71/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8525 - loss: 0.5027 - val_accuracy: 0.7925 - val_loss: 0.6655\n",
            "Epoch 72/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.7533 - loss: 0.8273 - val_accuracy: 0.7734 - val_loss: 0.6593\n",
            "Epoch 73/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.7863 - loss: 0.6560 - val_accuracy: 0.8676 - val_loss: 0.4285\n",
            "Epoch 74/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8585 - loss: 0.4701 - val_accuracy: 0.8680 - val_loss: 0.4250\n",
            "Epoch 75/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8506 - loss: 0.4861 - val_accuracy: 0.8621 - val_loss: 0.4294\n",
            "Epoch 76/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8546 - loss: 0.4878 - val_accuracy: 0.8764 - val_loss: 0.3950\n",
            "Epoch 77/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8696 - loss: 0.4292 - val_accuracy: 0.8606 - val_loss: 0.4698\n",
            "Epoch 78/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8430 - loss: 0.5275 - val_accuracy: 0.8613 - val_loss: 0.4355\n",
            "Epoch 79/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8523 - loss: 0.4831 - val_accuracy: 0.8684 - val_loss: 0.4339\n",
            "Epoch 80/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8497 - loss: 0.5016 - val_accuracy: 0.8751 - val_loss: 0.3900\n",
            "Epoch 81/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8438 - loss: 0.5144 - val_accuracy: 0.8494 - val_loss: 0.4612\n",
            "Epoch 82/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8301 - loss: 0.5542 - val_accuracy: 0.8512 - val_loss: 0.5035\n",
            "Epoch 83/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8328 - loss: 0.5603 - val_accuracy: 0.8643 - val_loss: 0.4645\n",
            "Epoch 84/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8428 - loss: 0.5481 - val_accuracy: 0.8521 - val_loss: 0.5746\n",
            "Epoch 85/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8306 - loss: 0.5624 - val_accuracy: 0.8716 - val_loss: 0.4244\n",
            "Epoch 86/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8491 - loss: 0.5039 - val_accuracy: 0.8699 - val_loss: 0.4973\n",
            "Epoch 87/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.5591 - val_accuracy: 0.8554 - val_loss: 0.4990\n",
            "Epoch 88/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8332 - loss: 0.5476 - val_accuracy: 0.8720 - val_loss: 0.4586\n",
            "Epoch 89/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8288 - loss: 0.5794 - val_accuracy: 0.8668 - val_loss: 0.4355\n",
            "Epoch 90/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8495 - loss: 0.5013 - val_accuracy: 0.8633 - val_loss: 0.4948\n",
            "Epoch 91/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8410 - loss: 0.5300 - val_accuracy: 0.8663 - val_loss: 0.4206\n",
            "Epoch 92/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8509 - loss: 0.5041 - val_accuracy: 0.8716 - val_loss: 0.4374\n",
            "Epoch 93/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8346 - loss: 0.5608 - val_accuracy: 0.8644 - val_loss: 0.4350\n",
            "Epoch 94/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8456 - loss: 0.5333 - val_accuracy: 0.8691 - val_loss: 0.4261\n",
            "Epoch 95/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8472 - loss: 0.4986 - val_accuracy: 0.8674 - val_loss: 0.4549\n",
            "Epoch 96/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8494 - loss: 0.4913 - val_accuracy: 0.8640 - val_loss: 0.4571\n",
            "Epoch 97/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 8ms/step - accuracy: 0.8353 - loss: 0.5386 - val_accuracy: 0.8620 - val_loss: 0.4585\n",
            "Epoch 98/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 8ms/step - accuracy: 0.8411 - loss: 0.5245 - val_accuracy: 0.8670 - val_loss: 0.4423\n",
            "Epoch 99/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8372 - loss: 0.5159 - val_accuracy: 0.8648 - val_loss: 0.4947\n",
            "Epoch 100/100\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.8330 - loss: 0.5896 - val_accuracy: 0.8462 - val_loss: 0.6861\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c753249dad0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs= 100, validation_data= (X_valid, y_valid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f7d01d65",
      "metadata": {
        "id": "f7d01d65"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}